{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing version with truncated pixels (5) in order to see the size of each matrix during forward and back propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas is for reading data\n",
    "import pandas as pd\n",
    "# numpy is for linear algebra\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv(\"data_files/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5\n",
       "0      1       0       0       0       0       0       0\n",
       "1      0       0       0       0       0       0       0\n",
       "2      1       0       0       0       0       0       0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small = data_1.iloc[0:3,0:7]\n",
    "data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = data.shape\n",
    "\n",
    "# In order to avoid overfitting, we want to randomize the data and then split it into train and dev\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# transpose the data so that each column is a row (easier)\n",
    "data_dev = data[0:10].T\n",
    "# each column is now an image\n",
    "# first row is now labels\n",
    "# following rows (783) are each pixel\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:]\n",
    "X_dev = X_dev / 255\n",
    "\n",
    "data_train = data.T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:]\n",
    "X_train = X_train / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (6, 3)\n",
      "Y_train:  (3,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape)\n",
    "print('Y_train: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # random.randn makes dist between -.5 and .5\n",
    "    # wi is the weight vector (# second layer neurons, # first layer neurons)\n",
    "        # each input neuron (784) connects to each output neuron (10)\n",
    "    # bi is the bias in the output layer neurons\n",
    "    w1 = np.random.randn(10,6)\n",
    "    b1 = np.random.randn(10,1)\n",
    "    w2 = np.random.randn(10,10)\n",
    "    b2 = np.random.randn(10,1)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: (10, 6) \n",
      "\n",
      "b1: (10, 1) \n",
      "\n",
      "w2: (10, 10) \n",
      "\n",
      "b2: (10, 1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = init_params()\n",
    "print('w1:', w1.shape, '\\n')\n",
    "print('b1:',b1.shape, '\\n')\n",
    "print('w2:',w2.shape, '\\n')\n",
    "print('b2:',b2.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    # maximum is element-wise so it runs that calc for each element in Z \n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z) / sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left off at 16:54\n",
    "def forward_prop(w1, b1, w2, b2, X):\n",
    "    print(\"Forward Propogation\")\n",
    "    z1 = w1.dot(X) + b1\n",
    "    print(\"z1: \", z1.shape)\n",
    "    A1 = ReLU(z1)\n",
    "    print(\"A1: \", A1.shape)\n",
    "    z2 = w2.dot(A1) + b2\n",
    "    print(\"z2: \", z2.shape)\n",
    "    A2 = softmax(z2)\n",
    "    print(\"A2: \", A2.shape)s\n",
    "    print(z1[0:5, 0:5])\n",
    "    print(A1[0:5, 0:5])\n",
    "    print()\n",
    "\n",
    "    return z1, A1, z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a vector Y of class labels into a one-hot encoded matrix\n",
    "# one-hot encoding is a common way to represent categorical variables as binary vectors \n",
    "# Y is going to be an array (mx1) where each element is the predicted class for the equivalent instance column of the input data array\n",
    "def one_hot(Y):\n",
    "    # np.zeros line creates a 2D array of zeros with shape determined by number of samples and number of unique classes   \n",
    "        # y.size returns the total number of elements in Y which represents the number of samples or instances\n",
    "        # Y.max() + 1 calculates the max value in Y and adds 1 to determine the number of unique classes\n",
    "            # adding one is necessary because the classes start from 0 (0-9)\n",
    "    print()\n",
    "    print(\"One hot encoding\")\n",
    "    print(\"Y \", Y, Y.size)\n",
    "    ohY = np.zeros((Y.size, 10))\n",
    "    # \"for each row, go to the column specified by the label in Y and set it equal to 1\"\n",
    "    # by indexing ohY like this, we are effectively selecting one position per row, determined by the class label in Y\n",
    "    # each row in ohY corresponds to a sample in Y and each column in ohY corresponds to a class\n",
    "    # for each row in ohY, the column corresponding to its class label is set to 1 (all other columns remain 0)\n",
    "        #  np.arange(Y.size) generates an array of indices from 0 to Y.size - 1 corresponding to each sample in Y --> specifies what row to access\n",
    "        # Y contains the class label for each sample\n",
    "            # when used as an index, Y selects the column in ohY that corresponds to its class label\n",
    "    # \n",
    "    ohY[np.arange(Y.size), Y] = 1\n",
    "    print('\\n',\"ohy \", ohY)\n",
    "    print(\"ohY.T \", ohY.T, ohY.T.size)\n",
    "    # transpose because we want each column to be a sample not each row\n",
    "    return ohY.T\n",
    "\n",
    "def deriv_ReLU(Z):\n",
    "    # relu has deriv of 1 for x > 0 (because x = x) and 0 for x <=0 (because x = 0)\n",
    "    # this works because booleans are converted to 1 for true and 0 for false so if a number is positive then its deriv was 1\n",
    "    # since\n",
    "    return Z > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(z1, A1, z2, A2, w2, X, Y):\n",
    "    print('Back Propogation')\n",
    "    m = Y.size\n",
    "    print(\"Y.size: \", Y.size)\n",
    "    ohY = one_hot(Y)\n",
    "    print(ohY, '\\n')\n",
    "    print(\"ohY: \", ohY.size)\n",
    "    dz2 = A2 - ohY\n",
    "    print('A2: ', A2.shape)\n",
    "    print('ohY: ', ohY.shape)\n",
    "    print('dz2: ', dz2.shape)\n",
    "    dw2 = 1/m * dz2.dot(A1.T)\n",
    "    print('A1.T: ', A1.T.shape)\n",
    "    print('dw2: ', dw2.shape)\n",
    "    db2 = 1/m * np.sum(dz2)\n",
    "    print('db2: ', db2.shape)\n",
    "    # I don't understand this next part\n",
    "    dz1 = w2.T.dot(dz2) * deriv_ReLU(z1)\n",
    "    print('w2.T: ', w2.T.shape)\n",
    "    print('z1: ', z1.shape)\n",
    "    print('dz1: ', dz1.shape)\n",
    "    dw1 = 1/m * dz1.dot(X.T)\n",
    "    print('X.T: ', X.T.shape)\n",
    "    print('dw1: ', dw1.shape)\n",
    "    db1 = 1/m * np.sum(dz1)\n",
    "    print('db1: ', db1.shape)\n",
    "    return dw1, db1, dw2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    w1 = w1 - lr*dw1\n",
    "    b1 = b1 - lr*db1.reshape(-1,1)\n",
    "    w2 = w2 - lr*dw2\n",
    "    b2 = b2 - lr*db2.reshape(-1,1)\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, '\\n', Y)\n",
    "    return np.sum(predictions==Y) / Y.size\n",
    "\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        z1, A1, z2, A2 = forward_prop(w1, b1, w2, b2, X)\n",
    "        dw1, db1, dw2, db2 = back_prop(z1, A1, z2, A2, w2, X, Y)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        if (i%10) == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            print(f\"Accuracy: {get_accuracy(get_predictions(A2), Y)}\")\n",
    "            print()\n",
    "\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Propogation\n",
      "z1:  (10, 3)\n",
      "A1:  (10, 3)\n",
      "z2:  (10, 3)\n",
      "A2:  (10, 3)\n",
      "[[ 1.07834963  1.07834963  1.07834963]\n",
      " [-0.45755739 -0.45755739 -0.45755739]\n",
      " [-1.25161158 -1.25161158 -1.25161158]\n",
      " [ 0.44264046  0.44264046  0.44264046]\n",
      " [ 0.8580418   0.8580418   0.8580418 ]]\n",
      "[[1.07834963 1.07834963 1.07834963]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.44264046 0.44264046 0.44264046]\n",
      " [0.8580418  0.8580418  0.8580418 ]]\n",
      "\n",
      "Back Propogation\n",
      "Y.size:  3\n",
      "\n",
      "One hot encoding\n",
      "Y  [1 1 0] 3\n",
      "\n",
      " ohy  [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "ohY.T  [[0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] 30\n",
      "[[0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "ohY:  30\n",
      "A2:  (10, 3)\n",
      "ohY:  (10, 3)\n",
      "dz2:  (10, 3)\n",
      "A1.T:  (3, 10)\n",
      "dw2:  (10, 10)\n",
      "db2:  ()\n",
      "w2.T:  (10, 10)\n",
      "z1:  (10, 3)\n",
      "dz1:  (10, 3)\n",
      "X.T:  (3, 6)\n",
      "dw1:  (10, 6)\n",
      "db1:  ()\n",
      "Iteration:  0\n",
      "[7 7 7] \n",
      " [1 1 0]\n",
      "Accuracy: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(X_train, Y_train, 1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
